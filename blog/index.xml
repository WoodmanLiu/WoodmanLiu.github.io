<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on A minimal Hugo website</title>
    <link>http://localhost:1313/blog/</link>
    <description>Recent content in Blogs on A minimal Hugo website</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 10 Feb 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>DDPM 数学原理推导</title>
      <link>http://localhost:1313/blog/ddpm-%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E6%8E%A8%E5%AF%BC/</link>
      <pubDate>Mon, 10 Feb 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/ddpm-%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E6%8E%A8%E5%AF%BC/</guid>
      <description>&lt;p&gt;首先明确生成任务的目标：训练一个神经网络模型，让它把一个从已知概率分布(如标准正态分布)中采样的数据，映射到与真实数据分布相似的结果。换句话说，模型通过学习将简单的随机输入转化为符合真实数据特性的样本，从而实现数据生成。DDPM (Denoising Diffusion Probabilistic Models) 包含两个主要过程：&lt;strong&gt;前向过程&lt;/strong&gt;和&lt;strong&gt;反向过程&lt;/strong&gt;。在前向过程中逐步向原始图像添加噪声，将数据从真实分布转化为简单的高斯分布；而反向过程从高斯噪声开始，逐步去噪，最终恢复数据分布。&lt;/p&gt;&#xA;&lt;h1 id=&#34;1-前向过程&#34;&gt;1. 前向过程&lt;/h1&gt;&#xA;&lt;p&gt;给定一个从真实数据分布中采样的图像 &lt;code&gt;$\mathbf{x}_0\sim q(\mathbf{x})$&lt;/code&gt;，我们逐步向其添加 &lt;code&gt;$T$&lt;/code&gt; 次高斯噪声，得到一系列带噪图像 &lt;code&gt;$\mathbf{x}_1,...,\mathbf{x}_T$&lt;/code&gt;，这个过程是一个马尔可夫链：&#xA;&lt;code&gt;$$\begin{equation}q(\mathbf{x}_t|\mathbf{x}_{t-1})=\mathcal{N}(\mathbf{x}_t;\sqrt{1-\beta_t}\mathbf{x}_{t-1}, \beta_t\mathbf{I})\label{eq1}\end{equation}$$&lt;/code&gt;&#xA;其中 &lt;code&gt;$\beta_t$&lt;/code&gt; 是一个控制噪声大小的参数，范围在 &lt;code&gt;$(0,1)$&lt;/code&gt; 且接近于零，该参数随着前向扩散过程的逐步进行而增大。定义 &lt;code&gt;$\alpha_t=1-\beta_t$&lt;/code&gt;，通过重参数化技巧，可以将上式改写为：&#xA;&lt;code&gt;$$\begin{equation}\mathbf{x}_t=\sqrt\alpha_t \mathbf{x}_{t-1}+\sqrt{1-\alpha_t}\boldsymbol{\epsilon}_{t-1}\label{eq2}\end{equation}$$&lt;/code&gt;&#xA;其中，&lt;code&gt;$\boldsymbol{\epsilon}_{t-1}\sim\mathcal{N}(\mathbf{0},\mathbf{I})$&lt;/code&gt;。这个公式可以这样形象地理解：把图像变淡一点，并在这个基础上撒一点噪声。定义 &lt;code&gt;$\bar{\alpha}_t=\prod_{s=1}^t\alpha_s$&lt;/code&gt;，并递归地进行推导：&#xA;&lt;code&gt;$$\begin{equation}\begin{split}\mathbf{x}_t&amp;amp;=\sqrt\alpha_t (\sqrt\alpha_{t-1} \mathbf{x}_{t-2}+\sqrt{1-\alpha_{t-1}}\boldsymbol{\epsilon}_{t-2})+\sqrt{1-\alpha_t}\boldsymbol{\epsilon}_{t-1}\\&amp;amp;=\sqrt{\alpha_t \alpha_{t-1}}\mathbf{x}_{t-2}+\sqrt{\alpha_t-\alpha_t\alpha_{t-1}}\boldsymbol{\epsilon}_{t-2}+\sqrt{1-\alpha_t\boldsymbol{\epsilon}_{t-1}}\\&amp;amp;=\sqrt{\alpha_t \alpha_{t-1}}\mathbf{x}_{t-2}+(1-\alpha_t\alpha_{t-1})\boldsymbol{\bar\epsilon}_{t-2}\\&amp;amp;=...\\&amp;amp;=\sqrt{\bar\alpha_t}\mathbf{x}_0+(1-\bar\alpha_t)\boldsymbol{\epsilon}\end{split}\label{eq3}\end{equation}$$&lt;/code&gt;&#xA;其中 &lt;code&gt;$\boldsymbol{\bar\epsilon}_{t-2}$&lt;/code&gt; 和 &lt;code&gt;$\boldsymbol{\epsilon}$&lt;/code&gt; 是标准正态分布叠加在一起的结果，它们仍然服从标准正态分布。由上式可以看出，当 &lt;code&gt;$t$&lt;/code&gt; 特别大时，&lt;code&gt;$\bar\alpha_t$&lt;/code&gt; 接近于零，&lt;code&gt;$\mathbf{x}_t$&lt;/code&gt; 就变成了零均值的高斯噪声。我们可以由 &lt;code&gt;$\mathbf{x}_0$&lt;/code&gt; 一步推导出 &lt;code&gt;$\mathbf{x}_t$&lt;/code&gt;：&#xA;&lt;code&gt;$$\begin{equation}q(\mathbf{x}_t|\mathbf{x}_0)=\mathcal{N}(\mathbf{x}_t;\sqrt{\bar\alpha_t}\mathbf{x}_0, (1-\bar\alpha_t)\mathbf{I})\label{eq4}\end{equation}$$&lt;/code&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;2-反向过程&#34;&gt;2. 反向过程&lt;/h1&gt;&#xA;&lt;p&gt;反向过程与前向过程相反，是一个去噪的过程。如果我们知道反向过程每一步的分布 &lt;code&gt;$q(\mathbf{x}_{t-1}|\mathbf{x}_t)$&lt;/code&gt;，那么就可以从一个随机的高斯噪声开始，逐步去噪，最终得到干净的数据。分布 &lt;code&gt;$q(\mathbf{x}_{t-1}|\mathbf{x}_t)$&lt;/code&gt; 很难直接求得，但加上条件 &lt;code&gt;$\mathbf{x_0}$&lt;/code&gt; 时，我们把反向过程的每一小步也近似为高斯分布，概率 &lt;code&gt;$q(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)$&lt;/code&gt; 是可处理的：&#xA;&lt;code&gt;$$\begin{equation}q(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)=\mathcal{N}(\mathbf{x}_{t-1};\tilde{\mu}_t,\tilde{\beta}_t\mathbf{I})\label{eq5}\end{equation}$$&lt;/code&gt;&#xA;根据贝叶斯公式：&#xA;&lt;code&gt;$$\begin{equation}q(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)=\frac{q(\mathbf{x}_t|\mathbf{x}_{t-1},\mathbf{x}_0)q(\mathbf{x}_{t-1}|\mathbf{x}_0)}{q(\mathbf{x}_t|\mathbf{x}_0)}\label{eq6}\end{equation}$$&lt;/code&gt;&#xA;DDPM 设定反向过程的每一小步也具有马尔可夫性质，所以有 &lt;code&gt;$q(\mathbf{x}_t|\mathbf{x}_{t-1},\mathbf{x}_0)=q(\mathbf{x}_t|\mathbf{x}_{t-1})$&lt;/code&gt;，因此式(&lt;code&gt;$\ref{eq6}$&lt;/code&gt;)等号右边的三个概率分布可以根据式(&lt;code&gt;$\ref{eq1}$&lt;/code&gt;)和式(&lt;code&gt;$\ref{eq4}$&lt;/code&gt;)写出具体的表达式。将这三个高斯分布和式(&lt;code&gt;$\ref{eq3}$&lt;/code&gt;)带入式(&lt;code&gt;$\ref{eq6}$&lt;/code&gt;)之后，按照式(&lt;code&gt;$\ref{eq5}$&lt;/code&gt;)高斯分布的形式，可以得到 &lt;code&gt;$q(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)$&lt;/code&gt; 的均值和方差：&#xA;&lt;code&gt;$$\begin{equation}\tilde{\mu}_t=\frac{1}{\sqrt{\alpha_t}}(\mathbf{x}_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon}_t)\label{eq7}\end{equation}$$&lt;/code&gt;&#xA;&lt;code&gt;$$\begin{equation}\tilde{\beta}_t=\frac{1-\overline{\alpha}_{t-1}}{1-\overline{\alpha}_t}\beta_t\label{eq8}\end{equation}$$&lt;/code&gt;&#xA;观察可知，反向过程每一小步的方差是已知的，因此只需要用一个神经网络模型去预测均值 &lt;code&gt;$\tilde{\mu}_t$&lt;/code&gt; 即可。而式(&lt;code&gt;$\ref{eq7}$&lt;/code&gt;)中除 &lt;code&gt;$\boldsymbol{\epsilon}_t$&lt;/code&gt; 以外均为已知量，因此预测均值只需要预测 &lt;code&gt;$\boldsymbol{\epsilon}_t$&lt;/code&gt;。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Git 连接失败解决方案</title>
      <link>http://localhost:1313/blog/git-%E8%BF%9E%E6%8E%A5%E5%A4%B1%E8%B4%A5%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</link>
      <pubDate>Sat, 25 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/git-%E8%BF%9E%E6%8E%A5%E5%A4%B1%E8%B4%A5%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</guid>
      <description>&lt;p&gt;当开启 VPN 连接 Github 时，需要确保代理配置正确：&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;git config --global http.proxy http://proxy 127.0.0.1:7897&#xA;git config --global https.proxy https://proxy 127.0.0.1:7897&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;代理 IP 地址在这里查看：&lt;br&gt;&lt;img src=&#34;http://localhost:1313/images/Github 连接失败解决方案/screenshot.png&#34; alt=&#34;screenshot&#34; style=&#34;width: 80%; height: auto&#34; /&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>使用 Hugo 和 Github 部署个人主页</title>
      <link>http://localhost:1313/blog/%E4%BD%BF%E7%94%A8-hugo-%E5%92%8C-github-%E9%83%A8%E7%BD%B2%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/</link>
      <pubDate>Sun, 12 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/blog/%E4%BD%BF%E7%94%A8-hugo-%E5%92%8C-github-%E9%83%A8%E7%BD%B2%E4%B8%AA%E4%BA%BA%E4%B8%BB%E9%A1%B5/</guid>
      <description>&lt;h1 id=&#34;1-基本配置&#34;&gt;1. 基本配置&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;安装 Hugo 之后，在包含 hugo.exe 的文件夹中打开 cmd 窗口，输入命令 &lt;code&gt;hugo new site dev&lt;/code&gt;，会在该目录下新建一个名为“dev”的文件夹。&lt;br&gt;&lt;img src=&#34;http://localhost:1313/images/使用 Hugo 和 Github 部署个人主页/step_1.1.png&#34; alt=&#34;step_1.1&#34; style=&#34;width: 80%; height: auto&#34; /&gt;&lt;/li&gt;&#xA;&lt;li&gt;将 hugo.exe 复制到 dev 文件夹，并将下载的 hugo 主题(以 XMin 为例)放到 dev/themes 文件夹。&lt;/li&gt;&#xA;&lt;li&gt;将 hugo 主题 exampleSite 文件夹中的内容 (content, layouts, hugo.yaml) 复制到 dev 文件夹，删除自带的 dev/hugo.toml。&lt;br&gt;&lt;img src=&#34;http://localhost:1313/images/使用 Hugo 和 Github 部署个人主页/step_1.3.png&#34; alt=&#34;step_1.3&#34; style=&#34;width: 80%; height: auto&#34; /&gt;&lt;/li&gt;&#xA;&lt;li&gt;在 dev 中打开 cmd 窗口，输入命令 &lt;code&gt;hugo server -D&lt;/code&gt;，并将服务器地址复制到网页打开。&lt;br&gt;&lt;img src=&#34;http://localhost:1313/images/使用 Hugo 和 Github 部署个人主页/step_1.4-1.png&#34; alt=&#34;step_1.4-1&#34; style=&#34;width: 80%; height: auto&#34; /&gt;&lt;br&gt;此时应该可以正常显示主页。&lt;br&gt;&lt;img src=&#34;http://localhost:1313/images/使用 Hugo 和 Github 部署个人主页/step_1.4-2.png&#34; alt=&#34;step_1.4-2&#34; style=&#34;width: 80%; height: auto&#34; /&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h1 id=&#34;2-修改配置&#34;&gt;2. 修改配置&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;通过 hugo.yaml 文件控制菜单。将 &lt;code&gt;About&lt;/code&gt; 和 &lt;code&gt;Subscribe&lt;/code&gt; 相关代码注释，主页的菜单就没有这两项了。&lt;code&gt;weight&lt;/code&gt; 控制菜单项的顺序，&lt;code&gt;weight&lt;/code&gt;值越小，菜单项越靠前。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
